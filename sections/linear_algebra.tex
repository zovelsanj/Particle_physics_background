\section{LINEAR ALGEBRA}
\subsection{Background Definitions}
A vector space $\textbf{V}$ over a field $\mathbb{F}$ is a set \{u, v, w, ...\} of vectors, 
together with a set \{a, b, c, ...\} of elements in $\mathbb{F}$ called scalars,
that is closed under the taking of linear combinations:
\begin{equation}
    \textit{u, v } \epsilon \textbf{ V} \textit{ and a, b } \epsilon \: \mathbb{F} \rightarrow \textit{au + bv } \epsilon \textbf{ V},
\end{equation}
and where 0v = 0 and 1v = v

A subspace of $\textbf{V}$ is a subset of $\textbf{V}$ that is also a $\textbf{vector space}$. An $\textbf{affine subspace}$
of $\textbf{V}$ is a translate of a subspace of $\textbf{V}$. The vector space $\textbf{V}$ is the direct sum of
two subspaces $\textbf{U}$ and $\textbf{W}$, written $\textbf{V}$ = $\textbf{U} \oplus \textbf{W}$, 
if $\textbf{U} \cap \textbf{W}$ = 0 (the only vector in common is the 
zero vector) and every vector v $\epsilon$ $\textbf{ V}$ can be written uniquely as
v = u + w for some u $\epsilon \textbf{ U}$and w $\epsilon \textbf{ W}$.

A set \{v$_i$\} of vectors is $\textbf{linearly independent}$ (over the field $\mathbb{F}$) if, for any
collection of scalars \{c$_i$\} $\subset$ $\mathbb{F}$,

\begin{equation}
    \sum_{i}^{}c_i v_i = 0 \text{ implies }
    c_i = 0 \; \forall \: i.
\end{equation}
Essentially this means that no member of a set of linearly independent vectors may
be expressed as a linear combination of the others.

A set $\textbf{B}$ of vectors is a $\textbf{spanning set}$ for $\textbf{V}$ (or, more simply, spans $\textbf{V}$ ) if every
vector in $\textbf{V}$ can be written as a linear combination of vectors from $\textbf{B}$. A spanning
set of linearly independent vectors is called a basis for the vector space. The cardinality of a basis
for $\textbf{V}$ is called the dimension of the space, written dim $\textbf{V}$.

Let $\textbf{V}$ and $\textbf{W}$ be vector spaces. A map $\textbf{T}$ : $\textbf{V} \rightarrow \textbf{W}$ is linear (or a homeomorphism)
if, $\forall \: \text{v}_1 , \text{v}_2 \: \epsilon \: \textbf{V}  \text{and  a}_1 , \text{a}_2 \: \epsilon \: \mathbb{F}$,
\begin{equation}
    \text{T}(\text{a}_1 \text{v}_1 + \text{a}_2 \text{v}_2) = \text{a}_1  \text{T v}_1 + \text{a}_2 \text{T v}_2
\end{equation}

The set of all v $\epsilon \: \textbf{V}$ such that T v = 0 is called the $\textbf{kernel}$ (or null space) of T,
written ker T; dim ker T is sometimes called the nullity of T. The set of all w $\epsilon \: \textbf{W}$ 
for which there exists a v $\epsilon \: \textbf{V}$ with T v = w is called the image (or range) of T,
written im T. The rank of T, rk T, is defined as dim im T.

If T is bijective it is called an $\textbf{isomorphism}$, in which case $\textbf{V}$ and $\textbf{W}$ are said to
be isomorphic; this is written as $\textbf{V}$ $\cong$ $\textbf{W}$ or, sloppily, $\textbf{V}$ = $\textbf{W}$ . Isomorphic vector
spaces are not necessarily identical, but they behave as if they were. A linear map from a vector space to itself is called an $\textbf{endomorphism}$, and if it is
a bijection it is called an $\textbf{automorphism}$. (Physicists tend to call an endomorphism a linear operator)
A linear map T is idempotent if T$^2$ = T . An idempotent endomorphism $\pi$: $\textbf{V} \rightarrow \textbf{V}$ 
is called a projection (operator). Remark: This is not to be confused with 
an orthogonal projection, which requires an inner product for its definition.

\paragraph{\textbf{Group homeomorphisms (Linear Mapping)}}
\begin{itemize}
    \item \textbf{Monomorphism: } Injective Mapping (one-to-one)
    \item \textbf{Epimorphism: } Surjective Mapping (onto)
    \item \textbf{Isomorphism: } Bijective Mapping (one-to-one and onto)
    \item \textbf{Endomorphism: } Linear Mapping from vector to itself (same domain and co-domain)
    \item \textbf{Automorphism: } Bijective Endomorphism (isomorphic endomorphism)
    \item \textbf{Automorphism: } Isomorphism of Smooth Manifolds (bijection where both function and its inverse are differential)
\end{itemize}


\subsection{Dual Space}
A linear functional on $\textbf{V}$ is a linear map f : $\textbf{V} \rightarrow \mathbb{F}$. The set $\textbf{V} ^\ast$  of all linear
functionals on $\textbf{V}$ is called the $\textbf{dual space}$ of $\textbf{V}$, and is often denoted as Hom($\textbf{V}$, $\mathbb{R}$).
If f is a linear functional and a is a scalar, a f is another linear functional, defined
by (a f)(v) = a f(v) (pointwise multiplication). Also, if f and g are two linear
functionals then we can obtain a third linear functional f + g by (f + g)(v) =
f(v) + g(v) (pointwise addition). These two operations turn $\textbf{V}^ \ast
$  into a vector space, and when one speaks of the dual space one always has 
this vector space structure in mind.
It is customary to write $<$v, f$>$  or  $<$f, v$>$ to denote f (v). When written this way
it is called the $\textbf{natural pairing}$ or dual pairing between $\textbf{V}$ and $\textbf{V}^ \ast$ .
Elements of $\textbf{V}^ \ast$ are often called covectors.

A \href{https://math.stackexchange.com/questions/240491/what-is-a-covector-and-what-is-it-used-for}{\textbf{Covector}} 
is simply a linear function from vectors to real numbers, $\alpha$:$\textbf{V} \rightarrow \mathbb{R}$. 
For an example of a covector, we have these functions $dx_i$ which
is not a length but a function that takes vectors and picks out the $i^{th}$
coordinate component, for example in $\mathbb{R}^3$:
\begin{equation}
    \begin{aligned}
        dx_1 (A\hat{e_1} + B\hat{e_2} + C\hat{e_3}) = A \\
        dx_2 (A\hat{e_1} + B\hat{e_2} + C\hat{e_3}) = B \\
        dx_3 (A\hat{e_1} + B\hat{e_2} + C\hat{e_3}) = C  \\
    \end{aligned}
\end{equation}

These functions form a basis in the space of covectors. 
Every linear function from vectors to the real numbers can be written as a linear combination of these functions:
\begin{equation}
    \alpha (v) = \sum_{i}^{} \alpha_i dx_i(v)
\end{equation}

If \{e$_i$\} is a basis of $\textbf{V}$ , there is a \href{https://math.stackexchange.com/questions/490342/what-is-meant-by-canonical}{canonical} dual basis or $\textbf{cobasis}$ \{$\theta_j$\} of $\textbf{V}*\ast$ ,
defined by e$_i$ , $\theta_j$ = $\delta_ij$ , where $\delta_ij$ is the $\textbf{Kronecker delta}$:

$\delta_ij = \left\{ 
  \begin{array}{ c l }
    1 & \quad \textrm{if } i=j, \\
    0 & \quad \textrm{otherwise} \\
  \end{array}
\right.$ 

Any element f $\epsilon \: \textbf{V}^ \ast$ can be expanded in terms of the dual basis as:
\begin{equation}
    f = \sum_{i}^{} f_i\theta_i
\end{equation}
where f$_i \: \epsilon \: \mathbb{F}$. The scalars f$_i$ are called the components of f with respect to the
basis \{$\theta_i$\}.

\newpage
\subsection{Inner Product}
Let $\mathbb{F}$ be a subfield of $\mathbb{C}$, and let $\textbf{V}$ be a vector space over $\mathbb{F}$. A \href{https://math.stackexchange.com/questions/2709888/what-is-a-sesquilinear-form}{\textbf{sesquilinear form}}
on $\textbf{V}$ is a map $\textit{g}$ : $\textbf{V} \times \textbf{V} \rightarrow \mathbb{F}$ satisfying the following two properties. For
all u, v, w $\epsilon \: \textbf{V}$ and a, b $\epsilon \: \mathbb{F}$, the map $\textit{g}$ is

1. \textbf{linear on the second entry:} $\textit{g}$(u, av + bw) = a$\textit{g}$(u, v) + b$\textit{g}$(u, w), and \\
2. \textbf{Hermitian:} $\textit{g}$(v, u) = $\overline{\text{g(u, v)}}$
where $\bar{\text{a}}$ is the complex conjugate of a.

These two properties together imply that $\textit{g}$ is \href{https://en.wikipedia.org/wiki/Antilinear_map#:~:text=5%20Citations-,Definitions%20and%20characterizations,is%20called%20conjugate%20homogeneous%20if}{\textbf{antilinear}} on the first entry: $\textit{g}$(au + bv, w) = $\bar{\text{a}}$$\textit{g}$(u, w) + $\bar{\text{b}}$$\textit{g}$(v, w).

However, if $\mathbb{F}$ is a real field (a subfield of $\mathbb{R}$) then $\bar{\text{a}}$ = a and $\bar{\text{b}}$ = b and the above
condition condition just says that $\textit{g}$ is linear on the first entry as well. In that case
we say that $\textit{g}$ is a \href{https://en.wikipedia.org/wiki/Bilinear_form}{\textbf{bilinear form}}. Moreover, the Hermiticity condition becomes
the symmetry condition $\textit{g}$(u, v) = $\textit{g}$(v, u), so a real sesquilinear form is in fact a
\textbf{symmetric bilinear form}. If the \href{https://en.wikipedia.org/wiki/Sesquilinear_form}{sesquilinear form} g is

3. \textbf{nondegenerate}, so that $\textit{g}$(u, v) = 0 for all v implies u = 0,

then it is called an \href{https://math.stackexchange.com/questions/56/what-is-an-inner-product-space}{\textbf{inner product}}. 
A vector space equipped with an inner product is called an \textbf{inner product space}.

\newpage
